{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module to get current directory folder\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# scraping modules\n",
    "import snscrape.modules.twitter as twitter\n",
    "import itertools\n",
    "\n",
    "# date and time manipulation\n",
    "import datetime\n",
    "import pytz\n",
    "tz = pytz.timezone(\"Etc/GMT\")\n",
    "\n",
    "\n",
    "# module for API\n",
    "import requests\n",
    "from requests import Request, Session\n",
    "from requests.exceptions import ConnectionError, Timeout, TooManyRedirects\n",
    "import json\n",
    "\n",
    "\n",
    "# sentiment analysis modules\n",
    "import preprocessor as p # filters the unwanted elements of the tweets\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer # sentiment analysis module\n",
    "SIA = SentimentIntensityAnalyzer()\n",
    "\n",
    "# technical (financial) indicators \n",
    "import ta  \n",
    "\n",
    "# machine learning modules\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting model as class (standard way of doing it)\n",
    "class LSTMClassifier(nn.Module):\n",
    "    # init method\n",
    "    def __init__(self, input_size, hidden_size,sequence_size,num_layers,dropout):\n",
    "        \n",
    "        # calling super constructor\n",
    "        super(LSTMClassifier,self).__init__()\n",
    "\n",
    "        # initializing all classes variables\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sequence_size = sequence_size\n",
    "        self.num_layers=num_layers\n",
    "        self.droput = dropout\n",
    "        \n",
    "        # creating the LSTM cell of specified dimensions and characteristics\n",
    "        self.lstm = nn.LSTM(input_size=self.input_size,hidden_size=self.hidden_size,num_layers=num_layers,batch_first=True,dropout=0.2)\n",
    "\n",
    "        # dimension reduction: we want the hidden state to be reducted to single output \n",
    "        self.linear = nn.Linear(in_features=hidden_size, out_features=1)\n",
    "\n",
    "        # sigmoid function so that output is between 0 and 1 (classification)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    # forward method to set \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # applying input of LSTM cells to get output and hidden states\n",
    "        lstm_out, self.hidden = self.lstm(x)\n",
    "        \n",
    "        # getting output between 0 and 1 from last hidden state output of LSTM netword\n",
    "        y_pred = self.sigmoid(self.linear(lstm_out[:,-1,:]))\n",
    "\n",
    "        return y_pred\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def launchPriceAPI():\n",
    "    url = 'https://pro-api.coinmarketcap.com/v1/cryptocurrency/listings/latest'\n",
    "    parameters = {'start':'1','limit':'50','convert':'USD'}\n",
    "    headers = {'Accepts': 'application/json', 'X-CMC_PRO_API_KEY': '0ee334e0-37a8-406f-9f8c-93543ff21e8e'}\n",
    "\n",
    "    session = Session()\n",
    "    session.headers.update(headers)\n",
    "\n",
    "    try:\n",
    "        response = session.get(url, params=parameters)\n",
    "        data = json.loads(response.text)\n",
    "        new_time = data['data'][0]['quote']['USD']['last_updated']\n",
    "        new_price = data['data'][0]['quote']['USD']['price']\n",
    "        new_volume = data['data'][0]['quote']['USD']['volume_24h']\n",
    "    except (ConnectionError, Timeout, TooManyRedirects) as e:\n",
    "        new_time = np.nan\n",
    "        new_price = np.nan\n",
    "        new_volume = np.nan\n",
    "    return new_time, new_price, new_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets2polarity(tweets_list):\n",
    "    neg_global = 0\n",
    "    pos_global = 0\n",
    "    if len(tweets_list)>0:\n",
    "        for tweet in tweets_list:\n",
    "            polarity = list(SIA.polarity_scores(p.clean(tweet)).values())\n",
    "            neg_global += polarity[0]\n",
    "            pos_global += polarity[1]\n",
    "        return [neg_global/len(tweets_list),pos_global/len(tweets_list)]\n",
    "    else: \n",
    "        return [0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_rounder(date_time_str, time_int):\n",
    "    date_time = datetime.datetime.strptime(date_time_str, \"%Y-%m-%dT%H:%M:%S.000Z\")\n",
    "    number = int(time_int[:-1])\n",
    "    unit = time_int[-1]\n",
    "    if unit == 'T':\n",
    "        rounded_date_time = date_time - datetime.timedelta(minutes=date_time.minute % number,seconds=date_time.second,microseconds=date_time.microsecond)\n",
    "    elif unit == 'H':\n",
    "        rounded_data_time = date_time - datetime.timedelta(hours=date_time.hours % number, minutes=date_time.minute,seconds=date_time.second,microseconds=date_time.microsecond)\n",
    "    elif unit == 'D':\n",
    "        rounded_date_time = date_time - datetime.timedelta(days=date_time.days % number, hours=date_time.hours, minutes=date_time.minute,seconds=date_time.second,microseconds=date_time.microsecond)\n",
    "        \n",
    "    return rounded_date_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newRow(new_time, new_price, new_volume, time_int):\n",
    "    # getting the date of today in string\n",
    "    today = datetime.datetime.strftime(datetime.datetime.now(), \"%Y-%m-%d\") \n",
    "\n",
    "    #creating generator for scraping\n",
    "    tweets = twitter.TwitterSearchScraper(f\"bitcoin since:{today} until: filter:has_engagement lang:en\").get_items()\n",
    "\n",
    "    # iterating through all tweets\n",
    "    tweets = itertools.islice(tweets, None)\n",
    "\n",
    "    # storing tweets in pandas dataframe\n",
    "    raw_df = pd.DataFrame(tweets)\n",
    "\n",
    "    # grouping by the time interval\n",
    "    grouped_df = raw_df.groupby(pd.Grouper(key='date',freq=f\"{time_int}\"))\n",
    "\n",
    "    # only keeping last row (last time interval that will be updated in the sequence)\n",
    "    df = pd.DataFrame(grouped_df.content.apply(list)).tail(1)\n",
    "\n",
    "    # getting polarity scores for all tweets in time interval\n",
    "    df[['neg','pos']]=df.content.apply(tweets2polarity).to_list()\n",
    "\n",
    "    # dropping tweets column\n",
    "    df.drop('content',axis=1,inplace=True)\n",
    "\n",
    "    # getting number of tweets in time interval\n",
    "    df['tweets'] = grouped_df.content.count()\n",
    "\n",
    "    # appending closing and volume to time interval\n",
    "    df[['close','volume']] = pd.DataFrame({'close': new_price,'volume': new_volume}, index=[tz.localize(time_rounder(new_time,time_int))])\n",
    "\n",
    "    df['rsi'] = np.nan\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # getting global parameters\n",
    "    with open(os.path.join(sys.path[0],'parameters.json')) as fp:\n",
    "        parameters = json.load(fp)\n",
    "        \n",
    "    TIME_INT = parameters['TIME_INT']\n",
    "    RSI_WINDOW = int(parameters['RSI_WINDOW'])\n",
    "    \n",
    "    # getting dataframe \n",
    "    old_df = pd.read_parquet(os.path.join(sys.path[0],'data/dataframe.parquet'))\n",
    "    \n",
    "    # removing first row to get dataframe of sequence_size\n",
    "    df = old_df.iloc[1:]\n",
    "    \n",
    "    # getting new price and volume of bitcoin\n",
    "    new_time, new_price, new_volume = launchPriceAPI()\n",
    "    \n",
    "    # getting new row for sequence with new price and volume and sentiment analysis\n",
    "    new_df = newRow(new_time=new_time, new_price=new_price, new_volume=new_volume,time_int=TIME_INT)\n",
    "    \n",
    "    # appending new row to dataframe\n",
    "    df = df.append(new_df,ignore_index=True)\n",
    "\n",
    "    # calculating rsi index\n",
    "    df['rsi'] = ta.momentum.RSIIndicator(close=df.close, window=RSI_WINDOW).rsi()\n",
    "    \n",
    "    # converting missing data (in format: NaN): \n",
    "        # negativity and positivity to 0\n",
    "        # closing, volume and rsi to last values \n",
    "    df.fillna({'neg':0,'pos':0},inplace=True)\n",
    "    df.close.ffill(inplace=True)\n",
    "    df.volume.ffill(inplace=True)\n",
    "    df.rsi.ffill(inplace=True)\n",
    "    \n",
    "    # saving updated dataframe\n",
    "    df.to_parquet(os.path.join(sys.path[0],'data/dataframe.parquet'))\n",
    "    \n",
    "    # removing first window_size columns as RSI needs at least window_size number of columns before computing (before: NA)\n",
    "    final_df = df.iloc[20:]\n",
    "    print(final_df)\n",
    "    \n",
    "    # converting dataframe to torch tensor\n",
    "    sequence = torch.Tensor(final_df.to_numpy()).unsqueeze(dim=1)\n",
    "    print(sequence.shape)\n",
    "    \n",
    "    # loading ML model\n",
    "    model = torch.load(os.path.join(sys.path[0],'pytorch_models/pretrained_model.pt'))\n",
    "    \n",
    "    # predicting value\n",
    "    y_pred = model(sequence)\n",
    "    \n",
    "    # formatting the value to dataframe for exporting\n",
    "    out = pd.DataFrame(y_pred, columns=[datetime.datetime.strftime(datetime.datetime.now(), \"%Y-%m-%d,%Hh%M\")])\n",
    "    \n",
    "    # exporting csv file\n",
    "    out.to_csv(os.path.join(sys.path[0],'data/live_preds.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
